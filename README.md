# Meeting Summarizer

This project provides an **AI-powered meeting transcription and summarization system** using **FastAPI** for the backend and **Streamlit** for the frontend.  
The system transcribes audio, refines the transcription, and generates structured summaries with key discussions, decisions made, and action items.

---

## ğŸ›  Setup Instructions

### 1ï¸âƒ£ Install Dependencies
Ensure you have Python (3.9 or above) installed, then install the required dependencies:

    pip install -r requirements.txt

### 2ï¸âƒ£ Set Up Environment Variables
Create a `.env` file in the root directory and add the following:

    GROQ_API_KEY=your_groq_api_key_here

Replace `your_groq_api_key_here` with your actual API key from [Groq](https://console.groq.com/).

---

## ğŸš€ Running the Application

### 1ï¸âƒ£ Start the FastAPI Backend
Run the following command to start the backend:

    uvicorn apiftest:app --reload

This will start the FastAPI server at `http://127.0.0.1:8000`.

### 2ï¸âƒ£ Start the Streamlit Frontend
Open another terminal and run:

    streamlit run app.py

This will launch the Streamlit UI for uploading audio files and viewing the transcriptions and summaries.

---

## ğŸ¤– Models Used

The project leverages **Groq AI models** and **OpenAI Whisper** for audio-to-text, refinement, and summarization tasks.

### 1ï¸âƒ£ Whisper (local)
- Developed by OpenAI.  
- Performs **speech-to-text transcription** locally for free.  
- Handles multiple languages and noisy environments effectively.  
- Used for converting meeting audio into text.

### 2ï¸âƒ£ Llama-3.1-8b-instant
- A fast, efficient **Groq LLM** optimized for real-time responses.  
- Used for **refinement** of transcriptions â€” fixing grammar, missing words, and improving coherence.  
- Ensures the meaning is preserved while improving readability.

### 3ï¸âƒ£ Llama-3.3-70b-versatile
- A large, powerful **Groq LLM** used for **structured summarization**.  
- Generates key discussion points, decisions made, and actionable tasks.  
- Provides concise, organized summaries for better understanding.

Together, these models ensure accurate transcriptions and meaningful, structured summaries with minimal human intervention.

---

## ğŸ“‚ Project Structure
    ğŸ“‚ Meeting_summarizer/
    â”‚-- apiftest.py        # FastAPI backend for processing audio and summarization
    â”‚-- app.py             # Streamlit frontend for user interaction
    â”‚-- main.py            # Local Whisper + Summarization alternative pipeline
    â”‚-- requirements.txt   # Required dependencies
    â”‚-- .env               # Environment variables (GROQ_API_KEY)
    â”‚-- README.md          # Project documentation

---

## ğŸ¯ Features
âœ… **Automatic Audio Transcription** using Whisper  
âœ… **Refined Transcription** with Llama-3.1-8b-instant  
âœ… **Structured Summarization** via Llama-3.3-70b-versatile  
âœ… **FastAPI Backend** for modular and scalable processing  
âœ… **Streamlit Frontend** for easy interaction and output visualization  
âœ… **Multi-format Support** for various audio files  

---

## ğŸ§© Supported Audio Formats
`wav`, `mp3`, `m4a`, `ogg`, `flac`

---

## ğŸ§  Workflow Overview

1ï¸âƒ£ User uploads an audio file through Streamlit.  
2ï¸âƒ£ FastAPI backend saves and processes the file.  
3ï¸âƒ£ Whisper model transcribes the audio into text.  
4ï¸âƒ£ Llama-3.1-8b-instant refines the transcription.  
5ï¸âƒ£ Llama-3.3-70b-versatile generates a structured summary.  
6ï¸âƒ£ Streamlit displays the complete results to the user.

---

## âš™ï¸ Example API Response

```json
{
  "message": "âœ… Audio processed successfully",
  "original_transcription": "Good morning everyone, let's start the meeting...",
  "refined_transcription": "Good morning everyone. Letâ€™s begin todayâ€™s meeting...",
  "structured_summary": "### Summary\n- Discussed project milestones.\n### Key Decisions\n- Extended deadline by 2 weeks.\n### Action Items\n- Task: Update project plan\n  - Assigned to: Raj\n  - Due date: Oct 20"
}
